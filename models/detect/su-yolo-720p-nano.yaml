# SU-YOLO 720p Nano — 60+ FPS, <15ms latency at 1280x720 on ZCU102
#
# Latency budget (single B4096 core @ 281MHz = 1.15 TOPS, 50-60% util):
#   Available: 8.6-10.3 GOPS per frame for <15ms latency
#   This model: ~4.5 GOPS → ~7.8ms single-core latency ✓
#   Throughput: 3 cores pipelined → ~130 FPS ✓
#
# VisDrone-specific optimizations:
#   - SEncoderLite: stride 2 first (cheap at Cin=3), then stride 1 at half-res
#   - P2 (stride 4) + P3 (stride 8) only — no P4 (drone objects are small)
#   - Explicit small channels — NOT relying on width_multiple (c4 bug)
#   - reg_max: 8 — lighter bbox distribution head
#   - time_step: 1 for DPU deployment
#
# Per-layer GOPS breakdown at 1280x736, time_step=1:
#   SEncoderLite (3→16):  0.64 GOPS  (stem)
#   BasicBlock1 (16→32):  0.43 GOPS  (P2/4)
#   BasicBlock1 (32→64):  0.43 GOPS  (P3/8)
#   Head (FPN + BB2):     0.55 GOPS  (neck)
#   SDDetect (P2+P3):     2.21 GOPS  (heads)
#   TOTAL:               ~4.5 GOPS
#
# Train: python train.py --cfg models/detect/su-yolo-720p-nano.yaml \
#          --data data/visdrone.yaml --img 736 --batch 32 --time-step 1
# Export: python export.py --weights best.pt --imgsz 736 1280 --include vitisai

# parameters
nc: 10  # VisDrone classes (overridden by data yaml at runtime)
depth_multiple: 1.0
width_multiple: 1.0  # explicit channels below — do NOT scale
reg_max: 8  # lighter bbox regression (default 16)

# anchors
anchors: 2

# backbone — 2-stage (P2+P3), no P4. Explicit small channels.
backbone:
  [
   # SEncoderLite: stride-2 first → halves spatial dims cheaply (Cin=3)
   # then stride-1 at 640x368 for feature extraction
   [-1, 1, SEncoderLite, [16, 3, 2]],  # 0-P1/2  16ch, 640x368

   # elan-1 block: 16→32ch, stride 2
   [-1, 1, BasicBlock1, [32, 32, 16, 1]],  # 1-P2/4  32ch, 320x184

   # elan-2 block: 32→64ch, stride 2
   [-1, 1, BasicBlock1, [64, 64, 32, 1]],  # 2-P3/8  64ch, 160x92
  ]

# head — P2/P3 two-scale FPN + detect
head:
  [
    # 1x1 channel reduce on P3
   [ -1, 1, SConv, [ 32, 1, 1 ] ],  # 3 — 64→32ch @ 160x92

    # upsample + concat with backbone P2
   [ -1, 1, SUpsample, [ 2 ] ],  # 4 — 32ch @ 320x184
   [ [ -1, 1 ], 1, SConcat, [ 1 ] ],  # 5 — cat → 64ch @ 320x184

    # elan-2 block for P2 output
   [ -1, 1, BasicBlock2, [ 32, 32, 16, 1 ] ],  # 6 (P2/4-small) 32ch

    # downsample + concat with head P3
   [-1, 1, SConv, [32, 3, 2]],  # 7 — 32ch @ 160x92
   [ [ -1, 3 ], 1, SConcat, [ 1 ] ],  # 8 — cat → 64ch @ 160x92

    # elan-2 block for P3 output
   [ -1, 1, BasicBlock2, [ 32, 32, 16, 1 ] ],  # 9 (P3/8-medium) 32ch

    # detect at P2 + P3 (2 scales)
   [ [ 6, 9 ], 1, SDDetect, [ nc ] ],  # SDDetect(P2, P3)
  ]
